# 爬虫案例

## 运行环境

> 1. python 搭建
> 2. pycharm 安装

## DOMO

#### 一、豆瓣TOP250

0. 导入

   ```py
   from bs4 import BeautifulSoup #构建树
   import re                     #正则
   import urllib.request         #url请求
   import urllib.error           #url报错
   import xlwt                   #表格
   ```

1. 批量获取网页

   ```py
   # 获取一个网页
   def askURL(url):
       # 浏览器F12获取头部ua
       head  = {
           "user-agent":"Mozilla / 5.0(Windows NT 10.0;Win64;x64) AppleWebKit / 537.36(KHTML, like Gecko) Chrome / 81.0.4044.122 Safari / 537.36"
       }
       request = urllib.request.Request(url,headers=head)
       html = ""
       try:
           response = urllib.request.urlopen(request)
           html = response.read().decode("utf-8")
       except urllib.error.URLError as e:
           if hasattr(e,"code"):
               print(e.code)
           if hasattr(e,"reason"):
               print(e.reason)
       return html
   ```

2. 获取网页数据

3. 保存筛选数据

#### 二、数据模型

1. 解析xml文件
2. 筛选xml数据
3. 保存数据

## 参考引用

> 1. B站：
>
>    python 爬虫技术5天速成——IT私塾





